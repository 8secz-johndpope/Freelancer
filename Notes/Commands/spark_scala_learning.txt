1. Reduce in spark using scala :

val new_agg_df = daily_df.join(
     agg_df,
     join_seq.map(c => daily_df(c) <=> agg_df(c)).reduceLeft( _&&_ ),
     “fullouter”)
     
2. Union of 2 DF require column to be in same order, so 2 nd df is arrange as 1st one:

 agg_df.columns.union(new_df,
 .select(
       agg_df.columns.toList.head, agg_df.columns.toList.tail: _*
     ))  

3. Align to table schema       
   val schema = sqlContext.table("table_name").schema
   val ff=finalTableDF.select(schema.fieldNames.map { finalTableDF(_) }:_*)
   
4. Increase the broadcast memory so that we can move from sort merge join to broadcast join:

 spark.conf.set("spark.sql.autoBroadcastJoinThreshold", 1024*1024*broadCastThresholdSizeInMB)
     
5. When OOM because of shuffle partitions:
spark.shuffle.io.preferDirectBufs='false'
spark.sql.shuffle.partitions = increase
spark.shuffle.registration.timeout: '600000'

6. Adaptive executions: New feature in spark, runtime decide on joining type (sort merge/broadcast hash join).
Skewness can also be removed in here.
 
7. Add below for Adding dependency for juypter:
%AddJar s3n://netflix-dataoven-prod/genie/jars/brickhouse.jar
Internal 
%AddDep netflix-core.jar

8. Add jar to spark sql function: 
sparkContext.sql or spark.sql("""ADD JAR s3n://netflix-dataoven-prod/genie/jars/brickhouse.jar""")
CREATE TEMPORARY FUNCTION COMBINE AS 'brickhouse.udf.collect.CombineUDF';
CREATE TEMPORARY FUNCTION CAST_ARRAY AS 'brickhouse.udf.collect.CastArrayUDF';

9. Filter condition in scala:
link_cache.filter(!$"destination_id".isin(root_list:_*)

Spark Shell setting conf:
--------------------------
spark.conf.set("hive.exec.dynamic.partition", "true")
spark.conf.set("hive.exec.dynamic.partition.mode", "nonstrict")

Spark create session specify conf:
----------------------------------
 val sparkSession = SparkSession
          .builder()
          .config(sparkConf)
          .appName("Test")
          .enableHiveSupport()
          .config("hive.exec.dynamic.partition", "true")
          .config("hive.exec.dynamic.partition.mode", "nonstrict")
          .getOrCreate()
